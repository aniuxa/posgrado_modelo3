# Introducción a la inferencia

## Paquetes

```{r}
if (!require("pacman")) install.packages("pacman")#instala pacman si se requiere
pacman::p_load(tidyverse,
               readxl,
               writexl, 
               haven,
               sjlabelled, 
               janitor,
               infer, 
               ggpubr,
               magrittr,
               gt,
               GGally,
               broom,
               DescTools,
               wesanderson,
               gtsummary,
               srvyr,
               car)
```


## Cargando los datos

Desde STATA

```{r}
tlaxt322 <- read_dta("./datos/tlaxt322.dta") %>% 
  clean_names() %>% 
  filter(r_def==0) %>% 
  filter(!c_res==2)

```

Desde Excel:

```{r}
ICI_2021 <- read_excel("./datos/ICI_2021.xlsx",
                               sheet = "para_importar") %>% 
  clean_names()

```


## Hipótesis e intervalos de confianza

### t-test

Este comando nos sirve para calcular diferentes tipos de test, que tienen como base la distribución t

<b>Univariado para estimación</b>

```{r}
t.test(tlaxt322$ing_x_hrs) # pero no tenemos los filtro
```

Un truco para poder utilizar funciones de base con formato *tidy*

```{r}
tlaxt322 %>% 
  filter(clase2==1) %>% #Filtro de ocupados
  filter(ing_x_hrs>0) %>% #Filtros de quienes reportaron ingresos
  with(
    t.test(ing_x_hrs)
  )
```

Vamos a quedarnos a con esta población objetivo:

<b>Univariado para hipótesis específica</b>

$$ H_o:\mu=40 $$ $$ H_{a1}: \mu < 40 $$ $$ H_{a2}: \mu \neq 40 $$ $$ H_{a3}: \mu > 40 $$ Si hacemos explícita la $H_0$

```{r}
tlaxt322 %>% 
  filter(clase2==1) %>% #Filtro de ocupados
  filter(ing_x_hrs>0) %>% #Filtros de quienes reportaron ingresos
  with(
    t.test(tlaxt322$ing_x_hrs, mu=40)
    )
```

Para hacer explícitas las hipótesis alternativas

```{r}
tlaxt322 %>% 
  filter(clase2==1) %>% #Filtro de ocupados
  filter(ing_x_hrs>0) %>% #Filtros de quienes reportaron ingresos
  with(
  t.test(tlaxt322$ing_x_hrs, mu=40, alternative = "two.sided") #default y de dos colas
    )
```

```{r}
tlaxt322 %>% 
  filter(clase2==1) %>% #Filtro de ocupados
  filter(ing_x_hrs>0) %>% #Filtros de quienes reportaron ingresos
  with(
  t.test(tlaxt322$ing_x_hrs, mu=40, alternative = "greater") # cola derecha
    )
```

```{r}
tlaxt322 %>% 
  filter(clase2==1) %>% #Filtro de ocupados
  filter(ing_x_hrs>0) %>% #Filtros de quienes reportaron ingresos
  with(
  t.test(tlaxt322$ing_x_hrs, mu=40, alternative = "less") # cola izquierda
    )
```

### Enchulando un poquito

Los resultados tienen la info, pero la podemos almacenar en un objeto. Con los cálculos de modelos es muy útil guardarlos para compararlos.

```{r}
t.test0<-tlaxt322 %>% 
  filter(clase2==1) %>% #Filtro de ocupados
  filter(ing_x_hrs>0) %>% #Filtros de quienes reportaron ingresos
  with(
    t.test(tlaxt322$ing_x_hrs, mu=40)
    )
```

Veamos si lo imprimimos

```{r}
t.test0
```

```{r}
broom::tidy(t.test0)
```

La función "tidy()" hace que el resultado se vuelva un "tibble", una tabla muy compatible con el tidyverse. Esto puede ser útil cuando queremos ir comparando estimaciones.

Anteriormente vimos con base cómo hacer inferencia. El paquete "infer" tiene también elementos para inferencia, pero en formato más compatible con tidyverse.

```{r}
tlaxt322 %>% 
  filter(clase2==1) %>% #Filtro de ocupados
  filter(ing_x_hrs>0) %>% #Filtros de quienes reportaron ingresos
  infer::t_test(response = ing_x_hrs, mu = 40)

```

Como vemos nos da el mismo resultado anterior, pero nos da directamente el resultado en formato tidy.

Si solo queremos el estimador de "t"

```{r}
tlaxt322 %>% 
t_stat(response = ing_x_hrs, mu = 40)

```

Más de este paquete <https://infer.netlify.app/>

### Prueba para proporción

Vamos a revisar la proporción de hombres y mujeres en términos de participación laboral.

El comando de base es menos flexible:

```{r}
prop<-table(tlaxt322[tlaxt322$clase1>0,]$clase1)
prop.test(prop)
```

Los filtros se complican un poco...

```{r}
tlaxt322 %>% 
  filter(eda>14 & eda<99) %>% 
  mutate(clase1=as_label(clase1)) %>% #oo
  tabyl(clase1)
```

Vamos a aprovechar para re-etiquetar la variable clase1

```{r}
etiqueta_pea<-c("PEA", "PNEA") # un vector con las etiquetas
```

```{r}
tlaxt322 %>% 
  filter(eda>14 & eda<99) %>% 
  sjlabelled::set_labels(clase1, labels=etiqueta_pea) %>% 
  mutate(clase1=as_label(clase1)) %>% 
  tabyl(clase1)

```

En formato tidy

```{r}

tlaxt322 %>% 
  filter(eda>14 & eda<99) %>% 
  with(
    table(clase1)
    ) %>% 
  prop.test()

```

En base necesita que se alimente de un objeto tipo table, el cual es menos manejable. Por eso utilizaremos más el paquete `{infer}`

```{r}
tlaxt322 %>% 
  filter(eda>14 & eda<99) %>% 
  set_labels(clase1, labels=etiqueta_pea) %>% 
  mutate(clase1=as_label(clase1)) %>%   
  infer::prop_test(clase1 ~ NULL  ,
             p=0.7, 
            alternative="less")


# Para que nos dé Z
tlaxt322 %>% 
  filter(eda>14 & eda<99) %>% 
  set_labels(clase1, labels=etiqueta_pea) %>% 
  mutate(clase1=as_label(clase1)) %>%   
  infer::prop_test(clase1 ~ NULL  ,
            p=0.7, 
            alternative="less",
            success = "PEA", # necesitamos establecer el éxito
            z=TRUE)

```




## Análisis de varianza
Análisis de varianza. Haremos la versión  más simple. Para ver el efecto de un factor sobre una variable cualitativa (oneway).
Revisaremos si la región de residencia de los trabajadores tiene un efecto en la distribución de los ingresos por trabajo. 

### Primero un gráfico
la ANOVA se basa en que nuestra variable es normal. Quitaremos los outliers

```{r}
lienzo_bi <-tlaxt322  %>% 
           filter(clase2==1  & !ing_x_hrs==0) %>% 
           ggplot(aes(x=log(ing_x_hrs), fill=as_factor(t_loc_tri), 
           color=as_factor(t_loc_tri),
           alpha=I(0.5)))

lienzo_bi + geom_density()
```

La prueba ANOVA o análisis de varianza, nos dice cuánto de nuestra variable se ve explicado por un factor.


$$H_o:\mu_1=\mu_2=\mu_3=\mu_4$$

$$H_a:\text{Alguna de las medias es diferente}$$

En los modelos es mul útil guardar nuestros resultados como un objeto
```{r}
anova<-tlaxt322  %>% 
    filter(clase2==1) %>% 
      with(aov(ing_x_hrs ~ as_factor(t_loc_tri)))

summary(anova)
```

Con tidy:

```{r}
tidy(anova)
```


### Comparación entre grupos
¿si es significativo cuáles diferencias entre los grupos lo son?
```{r}
TukeyHSD(anova)
```

### Supuestos de ANOVA

* Las observaciones se obtienen de forma independiente y aleatoria de la población definida por los niveles del factor
* Los datos de cada nivel de factor se distribuyen normalmente.
* Estas poblaciones normales tienen una varianza común. 

```{r}
#Prueba Bartlett para ver si las varianzas son iguales

tlaxt322  %>% 
    filter(clase2==1) %>% 
      with(bartlett.test(ing_x_hrs ~ as_factor(t_loc_tri)))


```
La prueba tiene una Ho "Las varianzas son iguales"

```{r}
#Test Normalidad 
tlaxt322  %>% 
  filter(clase2==1) %>% 
  filter(ing_x_hrs>0) %>% 
 with(
    ks.test(ing_x_hrs, "pnorm", mean=mean(ing_x_hrs), sd=sd(ing_x_hrs))
    )
```
La prueba tiene una Ho "La variable es normal"


**¿Qué hacer?**

### Kruskal-Wallis test

Hay una prueba muy parecida que se basa en el orden de las observaciones, y se lee muy parecida a la ANOVA
```{r}
kruskal<-tlaxt322  %>% 
    filter(clase2==1) %>% 
      with(
        kruskal.test(ing_x_hrs ~ as_factor(t_loc_tri))
        )

kruskal
```

Para ver las comparaciones tenemos que usar el `DunnTest()`, del paquete `{DescTools}`
```{r}

tlaxt322  %>% 
    filter(clase2==1) %>% 
      with(
        DescTools::DunnTest(ing_x_hrs ~ as_factor(t_loc_tri))
        )

```


#### Un gráfico coqueto:
Se hace con ggpubr

```{r}


tlaxt322  %>% 
  filter(clase2==1) %>% 
  ggpubr::ggviolin(x = "t_loc_tri", y = "ing_x_hrs", fill = "t_loc_tri",
                   add = "boxplot", add.params = list(fill = "white")) +
  stat_compare_means(label.y = 600)  # Add the p-value 

comparaciones <- list( c("1", "2"), c("2", "3"), c("1", "3"),
                       c("1", "4"), c("2", "4"), c("3", "4") )



#Un gráfiquito accesorio 2:

tlaxt322  %>% 
  filter(clase2==1) %>% 
  filter(ing_x_hrs>0) %>% 
  ggpubr::ggviolin(x = "t_loc_tri", y = "ing_x_hrs", fill = "t_loc_tri",
                   palette = wesanderson::wes_palette("GrandBudapest1", 4, type="discrete"),
                   add = "boxplot", add.params = list(fill = "white"))+
  stat_compare_means(comparisons = comparaciones, label = "p.signif")+ # Add significance levels
  stat_compare_means(label.y = 500)     # Add global the p-value 


```



## Factores de expansión 

### La función tally

El comando `tabyl()` del paquete `{janitor}` es muy útil pero no es compatible con los factores del expansión. En realidad, `tabyl()` nos ahorra un poco el hecho de tener que agrupar nuestra base en categorías y luego hacer un conteo para cada una de ellas. `tally()` es un comando que nos hace ese conteo y `group_by()` nos agrupa las observaciones de nuestra base de datos para hacer cualquier operación. 

```{r}
tlaxt322  %>% 
 group_by(as_label(sex)) %>% 
  tally(fac_tri) %>% #nombre del factor
  adorn_totals()  # Agrega total
```

Podemos usar funciones de `adorn_...` de `{janitor}`
```{r}
tlaxt322  %>% 
 group_by(as_label(sex)) %>% 
  tally(fac_tri) %>% #nombre del factor
  adorn_totals() %>% # Agrega total
  adorn_percentages("all")  %>% 
  adorn_pct_formatting()
```


## Otras formas
La función `count()` también permite dar pesos

```{r}
tlaxt322  %>% 
  dplyr::count(sex, niv_ins,  wt = fac_tri) 

```

Es compatible con etiquetas
```{r}
tlaxt322  %>% 
  count(as_label(sex), as_label(niv_ins),  wt = fac_tri) 
```

Podemos mover un poquito con pivot_wider para que se vea más a lo que acostumbramos a una tabla de frecuencias

```{r}
tlaxt322  %>% 
  mutate_at(vars(sex, niv_ins), as_label) %>% 
  count(sex, niv_ins,  wt = fac_tri) %>% 
  tidyr::pivot_wider(names_from = sex, 
              values_from = n)
```

```{r}
tlaxt322  %>% 
  mutate_at(vars(sex, niv_ins), as_label) %>% # otra forma de mutate y as_label
  count(sex, niv_ins,  wt = fac_tri) %>% 
  pivot_wider(names_from = sex, 
              values_from = n) %>%
  adorn_totals() %>% # Agrega total
  adorn_percentages("col")  %>% 
  adorn_pct_formatting()
```

#Diseño complejo

Hay muchos diseños muestrales, asumiremos el diseño simple, pero hay que revisar la documentación de la base
```{r}
# Muestreo aleatorio
tlax_srvy <- tlaxt322  %>%
  as_survey_design(weights = fac_tri)

```

Si revisamos las encuestas tiene un diseño complejo, hay estratos y unidades primarias de muestreo
```{r}

# Muestreo estratificado
tlax_srvy <- tlaxt322  %>%
  as_survey_design(
    upm,
    strata = est_d_tri,
    weights = fac_tri,
    nest = TRUE)

```


Como vemos esto es un archivo bien grande, por lo que mejor vamos a seleccionar un par de variables:

```{r}
# simple random sample
tlax_srvy <- tlaxt322  %>%
  select(upm,est_d_tri, fac_tri, starts_with("clase"),
         sex, eda, anios_esc, ing_x_hrs, fac_tri) %>% 
  as_survey_design(
    upm,
    strata = est_d_tri,
    weights = fac_tri,
    nest = TRUE)

```

Para una media ponderada
```{r}
tlax_srvy %>%
  filter(eda>14 & eda<99) %>% #filtro de edad para tabulados
  filter(clase2==1) %>% # sólo ocupados
  filter(ing_x_hrs>0) %>% # sólo con ingresos
  summarise(
    media_ponderada = survey_mean(ing_x_hrs, na.rm=T))

```

Este valor coincide con los datos publicados por INEGI, incluso el error estándar. Si queremos los intervalos de confianza:

```{r}
tlax_srvy %>%
  filter(eda>14 & eda<99) %>% #filtro de edad para tabulados
  filter(clase2==1) %>% # sólo ocupados
  filter(ing_x_hrs>0) %>% # sólo con ingresos
  summarize(
    media_ponderada = survey_mean(ing_x_hrs,
                                  vartype = "ci") )

```


```{r}
tlax_srvy %>%
  filter(eda>14 & eda<99) %>% #filtro de edad para tabulados
  filter(clase2==1) %>% # sólo ocupados
  filter(ing_x_hrs>0) %>% # sólo con ingresos
  summarize(
    mediana_ponderada = survey_median(ing_x_hrs,
                                  vartype = "ci") )

```

```{r}
tlax_srvy %>%
  mutate(sex=as_label(sex)) %>% 
  group_by(sex) %>% #variables cuali
  summarize(proportion = survey_mean(), # proporción
            total = survey_total() ) # totales
```