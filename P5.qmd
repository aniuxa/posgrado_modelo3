# Introducción a los modelos de regresión

## Paquetes


```{r}
if (!require("pacman")) install.packages("pacman")#instala pacman si se requiere
pacman::p_load(tidyverse,
               readxl,
               writexl, 
               haven,
               sjlabelled, 
               janitor,
               infer, 
               ggpubr,
               magrittr,
               gt,
               GGally,
               broom,
               DescTools,
               wesanderson,
               gtsummary,
               srvyr,
               car,
               sjPlot,
               performance, see,
               jtools, #ojo
               sandwich, 
               huxtable)
```


## Cargando los datos

Desde STATA y haciendo filtros para hacer el código más corto:

```{r}
tlaxt322 <- read_dta("./datos/tlaxt322.dta") %>% 
  clean_names() %>% 
  filter(r_def==0) %>% 
  filter(!c_res==2) %>% 
  filter(ing_x_hrs>0) %>% 
  filter(clase2==1) %>% 
  filter(anios_esc<99) %>% 
  mutate(log_ing_x_hrs=log(ing_x_hrs))

```



## Introducción a la regresión lineal

**La relación entre dos variables**

En términos *mincerianos*, los ingresos estarían explicados por la escolaridad y la experiencia...

```{r}
tlaxt322 %>% 
  ggplot() +
  aes(x=anios_esc, 
      y=log_ing_x_hrs) + 
  geom_point()

```

Cuando tenemos muchos casos es útil la opción "jitter"

```{r}
tlaxt322 %>% 
  ggplot() +
  aes(x=anios_esc, y=log_ing_x_hrs) + 
  geom_jitter()

```

También cambiar un poquito la transparencia...

```{r}
tlaxt322 %>% 
  ggplot() +
    aes(x=anios_esc, y=log_ing_x_hrs, alpha=I(0.5)) + 
  geom_jitter()

```

¿Cómo se ve la línea MCO ajustada por estos elementos?

```{r}
tlaxt322 %>% 
  ggplot() +
    aes(x=anios_esc, y=log_ing_x_hrs, alpha=I(0.5)) + 
  geom_jitter()+
  geom_smooth(method = lm)

```

## Prueba de hipótesis para la correlación

Una prueba de hipotésis sobe la correlación

```{r}
cor_test<-tlaxt322 %>% 
  with(
    cor.test(log_ing_x_hrs, 
             anios_esc, 
             use = "pairwise")) # prueba de hipótesis.

#dos modos de visualizar el resultado

cor_test 

tidy(cor_test)
```


## ¿cómo se ajusta la línea?

Este sería el modelo simple

$$y=\beta_o+\beta_1x +\epsilon$$

Donde los parámetros $\beta_o$ y $\beta_1$ describen la pendiente y el intercepto de la población, respectivamente.

```{r}
modelo<-tlaxt322 %>% 
  with(
    lm(log_ing_x_hrs~ anios_esc)
  )

modelo
```

Guardarlo en un objeto sirve de mucho porque le podemos "preguntar" cosas

```{r}

summary(modelo) # da todo menos la anova de la regresión
confint(modelo) # da los intervalos de confianza
anova(modelo) # esto sí da la anova de la regresión.

```

Para ver esto más guapo:

```{r}
modelo %>%
   gtsummary::tbl_regression() 
  #%>% 
  # add_significance_stars() %>% 
  # add_n() %>% 
  # add_glance_table()

```


## Diagnósticos

```{r}
plot(modelo)

```

### Outliers y Normalidad
```{r}
# Assessing Outliers
car::outlierTest(modelo) # Bonferonni p-value for most extreme obs

```


```{r}
ggpubr::ggqqplot(tlaxt322$log_ing_x_hrs)
```

### Homocedasticidad

```{r}
# non-constant error variance test
car::ncvTest(modelo)
# plot studentized residuals vs. fitted values 
car::spreadLevelPlot(modelo)
```

### Con el paquete `{performance}`

Hay varios chequeos múltiples útiles en este paquete:

```{r}
performance::check_model(modelo)
```


Y hacer un test de heterocedasticidad

```{r}
performance::check_heteroscedasticity(modelo)
```

## Regresión Lineal múltiple

### Agregando una variable categórica

¿Es igual la relación entre hombres y mujeres con los ingresos y la escolaridad?

```{r}
tlaxt322 %>% 
  ggplot() +
    aes(x=anios_esc, y=log_ing_x_hrs, alpha=I(0.5), color=as_label(sex)) + 
  geom_jitter()+
  geom_smooth(method = lm)
```


Cuando nosotros tenemos una variable categórica para la condición de sexo. [nota: seguimos haciendo el ejercicio, a pesar de que ya observamos en nuestro diagnóstico el modelo no cumple con los supuestos, pero lo haremos para fines ilustrativos]

```{r}
modelo1<-tlaxt322 %>% 
  mutate(sex = as_label(sex)) %>% 
  with(
    lm(log_ing_x_hrs ~ anios_esc + sex)
  )

summary(modelo1)
```


Este modelo tiene coeficientes que deben leerse "condicionados". Es decir, en este caso tenemos que el coeficiente asociado a la edad, mantiene constante el valor de sexo y viceversa. 

¿Cómo saber is ha mejorado nuestro modelo? Podemos comparar el ajuste con la anova, es decir, una prueba F
```{r}
pruebaf0<-anova(modelo, modelo1)
pruebaf0
```



Como puedes ver, el resultado muestra un Df de 1 (lo que indica que el modelo más complejo tiene un parámetro adicional) y un valor p muy pequeño (<.51). Esto significa que agregar el sexo al modelo lleva a un ajuste significativamente mejor sobre el modelo original.

Esto también lo podemos hacer con el paquete `{performance}`:

```{r}
performance::compare_performance(modelo, modelo1)
```

Y también podemos hacer una prueba:


```{r}
performance::test_performance(modelo, modelo1)
```

### Otra variable cuantitativa

Podemos seguir añadiendo variables sólo "sumando" en la función

```{r}
modelo2<- tlaxt322 %>% 
  mutate(sex=as_label(sex)) %>%
  with(
    lm(log_ing_x_hrs ~ anios_esc + sex + eda)
    )
summary(modelo2)
```


Y podemos ver si introducir esta variable afectó al ajuste global del modelo
```{r}
pruebaf1<-anova(modelo1, modelo2)
pruebaf1
```

Hoy que tenemos más variables podemos hablar de revisar dos supuestos más.

### Otros supuestos

Además de los supuestos de la regresión simple, podemos revisar estos otros. De nuevo, usaremos el paquete `{car}`

1. Linealidad en los parámetros (será más díficil entre más variables tengamos)

2. La normalidad también, porque debe ser multivariada

3. Multicolinealidad
La prueba más común es la de Factor Influyente de la Varianza (VIF) por sus siglas en inglés. La lógica es que la multicolinealidad tendrá efectos en nuestro R2, inflándolo. De ahí que observamos de qué variable(s) proviene este problema relacionado con la multicolinealidad.

Si el valor es mayor a 5, tenemos un problema muy grave.

```{r}
car::vif(modelo2)
```


### Paquete `{jtools}`

Un solo modelo:

```{r mytextable}

jtools::summ(modelo)

```

Si queremos errores robusto, estilo *STATA*:

```{r}
summ(modelo2,  robust = "HC1")

```
Si queremos estandarizar nuestras escalas:

```{r}
summ(modelo2,  scale=T)

```

También se pueden comparar modelos:

```{r}
export_summs(modelo, modelo1, modelo2)

```

También el paquete "sjPlot" tiene el comando "plot_model()"


```{r}
sjPlot::plot_model(modelo1)
sjPlot::plot_models(modelo, modelo1, modelo2)

```


## Post-estimación

### Las predicciones

Unos de los usos más comunes de los modelos estadísticos es la predicción

```{r}
sjPlot::plot_model(modelo2, type="pred", terms = "anios_esc")
```

También podemos incluir la predecciones para los distintos valores de las variables
```{r}
plot_model(modelo2, type="pred", terms = c("anios_esc","sex")) + theme_blank()
```

El orden de los términos importa:
```{r}
plot_model(modelo2, type="pred", terms = c("sex","anios_esc")) + theme_blank()
```

### Efectos marginales
Con los efectos marginales, por otro lado medimos el efecto promedio, dejando el resto de variables constantes.

```{r}
plot_model(modelo2, type="eff", terms = "anios_esc")
plot_model(modelo2, type="eff", terms = "sex")

```
¿Es el mismo gráfico que con "pred"? Veamos la ayuda

¿Y si queremos ver esta informaicón graficada?
```{r}
eff<-plot_model(modelo2, type="eff", terms = "anios_esc")
eff$data

```


```{r}
eff<-plot_model(modelo2, type="pred", terms = "anios_esc")
eff$data
```

## Extensiones del modelo de regresión

### Introducción a las interacciones

Muchas veces las variables explicativas van a tener relación entre sí. Por ejemplo ¿Las horas tendrá que ver con el sexo y afectan no sólo en intercepto si no también la pendiente? Para ello podemos introducir una interacción

```{r}
modelo_int1<-lm(log_ing_x_hrs ~ anios_esc * sex , data = tlaxt322, na.action=na.exclude)
summary(modelo_int1)
```

Esta interacción lo que asume es que las pendientes pueden moverse (aunque en este caso específico no lo hacen tanto porque no nos salió significativa)

```{r}
plot_model(modelo_int1, type="int", terms = c("sex", "anios_esc"))

```

### Efectos no lineales

#### Explicitando el logaritmo

```{r}
modelo_log<-tlaxt322 %>% 
  with(
    lm(log(ing_x_hrs) ~ log(eda) + sex))

summary(modelo_log)
```


```{r}
plot_model(modelo_log, type="pred", terms ="eda")

```

#### Efecto cuadrático (ojo con la sintaxis)

```{r}
modelo_quadr<-lm(log_ing_x_hrs ~ anios_esc + I(anios_esc^2) + sex, 
                 data=tlaxt322)
summary(modelo_quadr)

```

Quizás con un gráfico de lo predicho tenemos más claro lo que hace ese término

```{r}
plot_model(modelo_quadr, type="pred", terms = c("anios_esc"))

```
